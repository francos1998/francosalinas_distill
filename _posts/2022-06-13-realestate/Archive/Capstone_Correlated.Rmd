---
title: "Correlated Data: Capstone"
author: "Thu and Franco"
output: html_document
bibliography: Library.bib
---

## Loading libraries and importing data

```{r}
library(dplyr)
library(lubridate)
library(stringr)
library(ggplot2)
library(sf) #install.packages('sf')
library(spdep) #install.packages('spdep')
library(patchwork)
library(viridis)
library(tidycensus)
library(tidygeocoder)
library(dplyr)
library(googlesheets4)
library(readr)
library(tidyr)
library(gganimate)
library(gifski)
library(transformr)
```

List of companies: https://www.value.today/headquarters/california


```{r, warning=FALSE}
# Load company data
sf_companies_long <- read_csv("sf_companies.csv")

```

```{r}
# Load bay area data from 2009 to 2019

load('CapstoneDataThuFranco.RData')
```

## Data Processing

Transform from wide to long form to merge with Bay Area data

```{r}
# Convert sf_companies dataset from wide to long form 

sf_companies_long <- sf_companies_long %>%
  filter(year < 2020) # keep data from 2009 to 2019
```

Use the geocode package to get long and lat for the companies' addresses. 

```{r}
sf_companies_with_coordinates <- sf_companies_long %>%
  geocode(Address)
```

```{r}
## Use coordinates to match geographic shape and check for coordinate system to match Bay Area's

sf_companies_reshape <- st_as_sf(sf_companies_with_coordinates, coords = c("long", "lat"))
st_crs(sf_companies_reshape) = st_crs(bay_area_data_2009_2019_acs5)

# ## Calculating growth for companies
sf_companies_growth <- sf_companies_reshape %>%
   group_by(Name, Address) %>%
   mutate(PreviousYearEBITDA = lag(Yearly_EBITDA_million, n = 1, default = NA)) %>% 
   ungroup()

```

Extracting a separate dataset for merging with company data

```{r}
tract_dataset <- bay_area_data_2009_2019_acs5 %>% filter(year == 2019) %>% select(GEOID, geometry)
```

```{r}
## For year 2019 we have 2000 meters radius that we will look for intersections with the geometry variable of the tract level data. We are creating a variable that counts the number of tech companies and we store it in a matrix. 

tract_dataset$NumTechCompanies <- st_intersects(tract_dataset, st_buffer(sf_companies_growth %>% 
                                                                               filter(year == 2019), dist=2000)) %>% 
  lengths()

## Find average and total sum of financial info of close by companies by year and adds it to the data set with all geometries but not census data or company name. 

tract_data_with_company_name <- st_join(tract_dataset, st_buffer(sf_companies_growth, dist=2000))

tract_dataset_with_company_info <- tract_data_with_company_name %>% 
  group_by(GEOID, year) %>% 
  summarize(aggregate_EBITDA = sum(Yearly_EBITDA_million, na.rm=TRUE),
            aggregate_past_EBITDA = sum(PreviousYearEBITDA, na.rm=TRUE),
            EBITDA_growth = ((aggregate_EBITDA-aggregate_past_EBITDA)/aggregate_past_EBITDA), 
            NumTechCompanies = max(NumTechCompanies)) %>% 
  ungroup() %>% 
  filter(!is.na(year))


## This line of code is changing the value for meanEPS when it has no input (from NaN to NA), weird, it gives 2009 EBITDA lagged values 

tract_dataset_with_company_info$EBITDA_growth[is.nan(tract_dataset_with_company_info$EBITDA_growth)] = NA
tract_dataset_with_company_info$EBITDA_growth[is.infinite(tract_dataset_with_company_info$EBITDA_growth)] = NA

tract_dataset_with_company_info$EBITDA_growth[is.na(tract_dataset_with_company_info$EBITDA_growth)] = 0


tract_dataset_with_company_info$year = as.numeric(tract_dataset_with_company_info$year)

# Drop geometry in tract data with company info to merge with bay area data 

#tract_dataset_with_company_info_drop_geo <- st_drop_geometry(tract_dataset_with_company_info)


##For this data set we had year = NA values 
tract_dataset_with_company_info <- tract_dataset_with_company_info  %>%
  mutate(segment = case_when(
  EBITDA_growth >= 0.5 ~ "High Growth",
  EBITDA_growth >= 0.2 & EBITDA_growth < 0.5 ~ "Medium Growth",
  EBITDA_growth > 0 & EBITDA_growth < 0.2 ~ "Low Growth",
  EBITDA_growth <= 0 ~ "Low Growth",
  TRUE ~ as.character(EBITDA_growth)
))


county_growth_assignment <- tract_dataset_with_company_info %>% 
  select(GEOID, segment,year) %>% 
  distinct() %>%
  arrange(GEOID) %>% 
  st_drop_geometry()


# Create population change column

bay_area_data_2009_2019_acs5 <- bay_area_data_2009_2019_acs5 %>%
  group_by(GEOID, NAME) %>%
  mutate(PreviousYearPop = lag(PopE, n = 1, default = NA)) %>% 
  ungroup() %>%
  arrange(GEOID, year)

bay_area_data_2009_2019_acs5 <- bay_area_data_2009_2019_acs5 %>%
  mutate(PopGrowth = (PopE - PreviousYearPop)/PreviousYearPop)

# Create income change column

bay_area_data_2009_2019_acs5 <- bay_area_data_2009_2019_acs5 %>%
  group_by(GEOID, NAME) %>%
  mutate(PreviousYearIncome = lag(IncomeE, n = 1, default = NA)) %>% 
  ungroup() %>%
  arrange(GEOID, year)

bay_area_data_2009_2019_acs5 <- bay_area_data_2009_2019_acs5 %>%
  mutate(IncomeGrowth = (IncomeE - PreviousYearIncome)/PreviousYearIncome)

# Create column # of people per house

bay_area_data_2009_2019_acs5_data <- bay_area_data_2009_2019_acs5_data %>%
  mutate(NumPeoplePerHouse = PopE/NumHouseE)


longitudinal_data <- left_join(bay_area_data_2009_2019_acs5, county_growth_assignment, by = c("GEOID","year"))
longitudinal_data$segment[is.na(longitudinal_data$segment)] = "Control"

spatial_data <- longitudinal_data %>% 
  filter(year == 2018)

```


```{r}
# Remove empty geo data
spatial_data_no_empty_geo <- spatial_data %>%
  filter(!st_is_empty(.)) 

```




```{r}

#Analyzing correlation with variable of interest

spatial_data_no_empty_geo %>% 
  ggplot(aes(x = segment, y = NumHouseE))+
  geom_boxplot() + 
  theme_classic()

spatial_data_no_empty_geo %>% 
  ggplot(aes(x = segment, y = PopGrowth))+
  geom_boxplot() + 
  theme_classic()

spatial_data_no_empty_geo %>% 
  ggplot(aes(x = segment, y = IncomeGrowth))+
  geom_boxplot()
spatial_data_no_empty_geo %>% 
  ggplot(aes(x = segment, y = NumPeoplePerHouse))+
  geom_boxplot() + 
  theme_classic()


spatial_data_no_empty_geo%>%
  mutate(segment = as.factor(segment), 
         PopGrowth = as.numeric(PopGrowth), 
         IncomeE = as.numeric(IncomeE)) %>% 
  select(PopGrowth, IncomeE, PopE,AgeE,HouseValueE,HouseholdSizeE,NumHouseE,PopGrowth,IncomeGrowth,NumPeoplePerHouse) %>%
  st_drop_geometry() %>%
  cor(.,use='complete.obs')

```

```{r}
# Fit OLS Model
spatial_data_no_empty_geo <- spatial_data_no_empty_geo %>%
  drop_na(HouseValueE, segment, IncomeE, AgeE, HouseholdSizeE, IncomeGrowth) %>% 
  st_as_sf()

lm1 <-lm(HouseValueE ~  segment + IncomeE + AgeE + HouseholdSizeE, data = spatial_data_no_empty_geo)
summary(lm1)

lm2 <-lm(HouseValueE ~ segment + IncomeE + AgeE + HouseholdSizeE + IncomeGrowth, data = spatial_data_no_empty_geo)
summary(lm2)

lm3 <-lm(HouseValueE ~ segment + IncomeE + HouseholdSizeE, data = spatial_data_no_empty_geo)
summary(lm3)

BIC(lm1)
BIC(lm2)
BIC(lm3)



spatial_data_no_empty_geo$lm_resid <- resid(lm3) 

spatial_data_no_empty_geo %>% 
  ggplot() +
  geom_sf(aes(fill = lm_resid), size = 0) +
  scale_fill_gradient2(mid = "white", high = "red", low = "blue") +
  theme_classic() 


```

```{r}
bay_area_centroids <- st_centroid(st_geometry(spatial_data_no_empty_geo), of_largest_polygon = TRUE)


KNN <- knn2nb(knearneigh(bay_area_centroids, k = 3)) #Trying

nb_KNN_net <- nb2lines(nb = KNN, coords = bay_area_centroids, as_sf = TRUE)


Wb <- nb2listw(KNN, style = "B")
# Ww <- nb2listw(KNN, style = "W") 

#When trying a Weighted or binary neighborhood structure we find the same values --> yes cuz it's same for KNN

spdep::moran.test(spatial_data_no_empty_geo$lm_resid, Wb, alternative = "two.sided", randomisation = TRUE)
# spdep::moran.test(spatial_data_no_empty_geo$lm_resid, Ww, alternative = "two.sided", randomisation = TRUE)

#there is significant evidence to reject the null hypothesis that the residuals are independent and identically distributed


mp <- spdep::moran.plot(spatial_data_no_empty_geo$lm_resid, Wb, plot=FALSE)
ggplot(mp, aes(x = x, y = wx)) + 
  geom_point() + 
  geom_smooth(method="lm" , se = FALSE) + 
  geom_hline(yintercept=mean(mp$wx), lty=2) + 
  geom_vline(xintercept=mean(mp$x), lty=2) + theme_classic() + 
  xlab('Residuals') + ylab("Average Residual of Neighbors")+
  ggtitle("Correlation of Residuals")
# From the linear plot we can also see that there is positive and negative correlation between the residuals and the average residuals of the neighbors. There is areas with positive and negative residuals. 

```

```{r}
 spatial_data_no_empty_geo%>%
  ggplot() + 
  geom_sf(fill = 'white', size = .05) + 
  geom_sf(data = nb_KNN_net, size = .05, color = 'blue')+
  theme_classic()
```

```{r}
library(spatialreg) #install.packages('spatialreg')

Ww <- nb2listw(KNN, style = "W")

# Fit SAR Model
mod_sar <- spatialreg::spautolm(formula = HouseValueE ~ segment + IncomeE + HouseholdSizeE, data = spatial_data_no_empty_geo, listw = Ww, family = "SAR")

summary(mod_sar)
BIC(mod_sar) # This BIC is slightly lower than CAR's 



```



```{r}
# Testing the residuals of the SAR model to see if the resulting residuals are independent or spatially correlated

spatial_data_no_empty_geo$sar_resid <- resid(mod_sar)

spatial_data_no_empty_geo%>% ggplot() +
 geom_sf(aes(fill = sar_resid),size=.05) +
 scale_fill_gradient2(mid = "white", high = "red", low = "blue") + theme_classic()

spdep::moran.test(spatial_data_no_empty_geo$sar_resid, Wb, alternative = "two.sided", randomisation = TRUE)  # Using randomization test
```

```{r}
#Fit CAR Model
mod_car <- spautolm(formula = HouseValueE ~ segment + IncomeE + HouseholdSizeE, data = spatial_data_no_empty_geo, listw = Ww, family = "CAR")

summary(mod_car)
BIC(mod_car)
```

```{r}
# Mapping and testing the residuals of the CAR model to see if the resulting residuals are independent or spatially correlated.
# spatial_data_no_empty_geo$car_resid <- resid(mod_car)
# 
# spatial_data_no_empty_geo %>% ggplot() +
#   geom_sf(aes(fill = car_resid)) +
#   scale_fill_gradient2(mid = "white", high = "red", low = "blue") + theme_classic()
# 
# spdep::moran.test(spatial_data_no_empty_geo$car_resid, Wb, alternative = "two.sided", randomisation = TRUE)  # Using randomization test
```

```{r}
# install.packages('spaMM')
library(spaMM)

spatial_data_no_empty_geo_2 <- as(spatial_data_no_empty_geo, "Spatial")

spamm <- fitme(HouseValueE ~ segment + IncomeE + HouseholdSizeE, data = as.data.frame(spatial_data_no_empty_geo_2),
    fixed = list(nu = 0.5))

summary(spamm)
```

```{r}
spatial_data_no_empty_geo$spamm_resid <- resid(spamm)


spatial_data_no_empty_geo %>%
    ggplot(aes(fill = spamm_resid), size = 0) +
    geom_sf() +
    scale_fill_gradient2(mid = "white", high = "red", low = "blue") +
    theme_classic()
```

```{r}
spdep::moran.test(spatial_data_no_empty_geo$spamm_resid, nb2listw(KNN, style = "W"), alternative = "two.sided")  # Using randomization
```


```{r}
# Create explanatory plots here 

## With NumTechCompanies -- not really good
# ggplot(merged_company_census_data_2019, aes(x=NumTechCompanies,y=HouseValueE)) + 
#   geom_point(color = "blue") + 
#   labs(title = "") +
#   theme_classic()

## With Population Growth -- not really good
ggplot(merged_company_census_data_2019, aes(x=PopGrowth,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

## With Income -- good
ggplot(merged_company_census_data_2019, aes(x=IncomeE,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

## With Aggregate EBIT Growth
ggplot(merged_company_census_data_2019, aes(x=EBITDA_growth,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  geom_smooth()
  labs(title = "") +
  theme_classic()


## With Household Size -- negative relationship

ggplot(merged_company_census_data_2019, aes(x=HouseholdSizeE,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

## With Number of House -- unclear rela

ggplot(merged_company_census_data_2019, aes(x=NumHouseE,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

## With Age -- positive rela

ggplot(merged_company_census_data_2019, aes(x=AgeE,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

## With Income Growth -- quite

ggplot(merged_company_census_data_2019, aes(x=IncomeGrowth,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

ggplot(merged_company_census_data, aes(x=IncomeGrowth,y=HouseValueE, group = year)) + 
  geom_line() + 
  labs(title = "") +
  theme_classic()

## With Income Growth

ggplot(merged_company_census_data_2019, aes(x=IncomeGrowth,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

## With Num People Per Household -- it's not this -- it's relatively the same

ggplot(merged_company_census_data_2019, aes(x=NumPeoplePerHouse,y=HouseValueE)) + 
  geom_point(color = "blue") + 
  labs(title = "") +
  theme_classic()

ggplot(merged_company_census_data_2019, aes(x=EBITDA_growth,y=IncomeE)) + 
  geom_point(color = "blue") + 
  geom_smooth()+
  labs(title = "") +
  theme_classic()



```







```{r}
## Graph by number of companies
merged_company_census_data %>% 
  filter(year == 2009) %>% 
ggplot() + 
  geom_sf(aes(fill = NumTechCompanies), size = 0.1) + 
  scale_fill_viridis(option = "A") +
  theme_classic() + 
  theme(legend.position = "bottom", legend.key.size = unit(1.1, 'cm'))

## Graph by meanEPS
merged_company_census_data %>% 
  filter(year == 2011) %>% 
ggplot() + 
  geom_sf(aes(fill = meanEPSGrowth), size = 0.1) + 
  scale_fill_viridis(option = "A") +
  theme_classic() + 
  theme(legend.position = "bottom", legend.key.size = unit(1.1, 'cm'))

merged_company_census_data %>% 
  filter(year == 2015) %>% 
ggplot() + 
  geom_sf(aes(fill = meanEPSGrowth), size = 0.1) + 
  scale_fill_viridis(option = "A") +
  theme_classic() + 
  theme(legend.position = "bottom", legend.key.size = unit(1.1, 'cm'))

merged_company_census_data %>% 
  filter(year == 2019) %>% 
ggplot() + 
  geom_sf(aes(fill = meanEPSGrowth), size = 0.1) + 
  scale_fill_viridis(option = "A") +
  theme_classic() + 
  theme(legend.position = "bottom", legend.key.size = unit(1.1, 'cm'))

#Understanding earnings per share across years for different companies
sf_companies_growth %>% 
  ggplot(aes(x = year, y = YearlyEPS, color = company_name))+
  geom_point()+
  facet_wrap(~company_name)+
  theme(axis.ticks.x = element_blank(), axis.text.x = element_blank())

#Understanding the mean EPS trend across all companies

sf_companies_growth %>% 
  group_by(year) %>%
  summarise(meanEPS = mean(YearlyEPS)) %>% 
  ggplot(aes(x = year, y = meanEPS))+
  geom_point()+
  geom_smooth()+
  theme_minimal()

```






```{r}
ggplot(bay_area_data) + 
  geom_sf(aes(fill = HouseValueE), size = 0.1) + 
  scale_fill_viridis(option = "A") +
  theme_classic() + 
  theme(legend.position = "bottom", legend.key.size = unit(1.1, 'cm'))
```

```{r, message=FALSE, warning=FALSE}
ggplot(bay_area_with_company_info_clean, aes(x = long, y = lat)) + 
  geom_point() + 
  scale_color_viridis_c() +
  coord_equal() + 
  labs(title = 'Tech Company Spatial Visualizations') +
  theme_classic()
```

```{r}
company_geo_data <- sf_companies_reshape %>% select(Name, geometry) %>% distinct()

##Graph by number of companies
p_income <- ggplot(merged_company_census_data_2019) + 
  geom_sf(aes(fill = IncomeE), size = 0.1) + 
  geom_sf(data = company_geo_data) +
  scale_fill_viridis(option = "A") +
  theme_classic() + 
  theme(legend.position = "bottom", legend.key.size = unit(1.1, 'cm'))

p_growth <- ggplot(merged_company_census_data_2019) + 
  geom_sf(aes(fill = EBITDA_growth), size = 0.1) + 
  geom_sf(data = company_geo_data) +
  scale_fill_viridis(option = "A") +
  theme_classic() + 
  theme(legend.position = "bottom", legend.key.size = unit(1.1, 'cm'))
```

```{r}
company_geo_data_test <- sf_companies_with_coordinates %>% select(Name, long, lat) %>% distinct()

p_name_comp <- ggplot(company_geo_data_test, aes(x=long, y=lat)) +
  geom_point()+
  geom_text(aes(label = Name)) +
  theme_classic()
  
```

```{r}
p_income|p_growth|p_name_comp
```


Next steps!

For Spatial: linear model with basic census data: income, pop, house value, not integrating EBITDA growth + SAR

For Longitudinal: looking at counties that have EBITDA growth. we're gonna create company groups (high growth, low growth)

Question: how do we incorporate counties into longitudinal? 

Probably use marin and san mateo as control? 





LINEAR MODEL INCORPORATING THE EXPLANATORY VARIABLES THAT HAVE A STRONG CORRELATION. 



